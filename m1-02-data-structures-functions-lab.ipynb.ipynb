{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2457bd-ad6b-48d5-87ce-8b97e9209ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 200\n",
      "Sample: [{'ticket_id': 1000, 'customer_id': 118, 'category': 'TECHNICAL  ', 'resolution_minutes': None, 'escalated': True}, {'ticket_id': 1001, 'customer_id': 144, 'category': 'Billing', 'resolution_minutes': 18, 'escalated': True}, {'ticket_id': 1002, 'customer_id': 106, 'category': 'General', 'resolution_minutes': None, 'escalated': True}, {'ticket_id': 1003, 'customer_id': 136, 'category': 'Billing', 'resolution_minutes': 8, 'escalated': True}, {'ticket_id': 1004, 'customer_id': 118, 'category': 'General', 'resolution_minutes': 80, 'escalated': True}]\n"
     ]
    }
   ],
   "source": [
    "#task 1\n",
    "import random\n",
    "\n",
    "def generate_raw_data(n=200):\n",
    "    random.seed(42)\n",
    "    categories = [\"Technical\", \"Billing\", \"Account\", \"General\"]\n",
    "    raw_logs = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Intentionally messy data: varying case and extra whitespace\n",
    "        category = random.choice(categories)\n",
    "        if i % 5 == 0:\n",
    "            category = category.upper() + \"  \"\n",
    "            \n",
    "        # Intentionally missing resolution times\n",
    "        res_min = random.randint(5, 120) if random.random() > 0.1 else None\n",
    "        \n",
    "        ticket = {\n",
    "            \"ticket_id\": 1000 + i,\n",
    "            \"customer_id\": random.randint(101, 150),\n",
    "            \"category\": category,\n",
    "            \"resolution_minutes\": res_min,\n",
    "            \"escalated\": random.choice([True, False])\n",
    "        }\n",
    "        raw_logs.append(ticket)\n",
    "    return raw_logs\n",
    "\n",
    "raw_data = generate_raw_data()\n",
    "print(f\"Total Records: {len(raw_data)}\")\n",
    "print(\"Sample:\", raw_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7253ecbe-6c41-49af-8053-c80c3be6be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report:\n",
      "- Records with missing resolution: 22\n",
      "- Records with missing keys: 0\n"
     ]
    }
   ],
   "source": [
    "#task 2 Design validation helpers\n",
    "def get_invalid_resolution_indices(data):\n",
    "    \"\"\"Identifies records where resolution_minutes is missing or None.\"\"\"\n",
    "    invalid_indices = []\n",
    "    for i, record in enumerate(data):\n",
    "        # Check if the key exists and if the value is None\n",
    "        if record.get(\"resolution_minutes\") is None:\n",
    "            invalid_indices.append(i)\n",
    "    return invalid_indices\n",
    "\n",
    "def check_missing_keys(data, required_keys):\n",
    "    \"\"\"Checks if any record is missing mandatory dictionary keys.\"\"\"\n",
    "    missing_key_indices = []\n",
    "    for i, record in enumerate(data):\n",
    "        if not all(key in record for key in required_keys):\n",
    "            missing_key_indices.append(i)\n",
    "    return missing_key_indices\n",
    "\n",
    "# --- Execution & Validation ---\n",
    "required = [\"ticket_id\", \"customer_id\", \"category\", \"resolution_minutes\", \"escalated\"]\n",
    "missing_res_indices = get_invalid_resolution_indices(raw_data)\n",
    "missing_keys_indices = check_missing_keys(raw_data, required)\n",
    "\n",
    "print(f\"Validation Report:\")\n",
    "print(f\"- Records with missing resolution: {len(missing_res_indices)}\")\n",
    "print(f\"- Records with missing keys: {len(missing_keys_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65cb7c-77df-4ff4-95c2-22ff789d6ac3",
   "metadata": {},
   "source": [
    "### task2\n",
    "Before cleaning the data, I created validation functions to audit the \"health\" of the raw dataset.\n",
    "\n",
    "Design Decisions:\n",
    "Function Purpose: These functions are \"read-only.\" They return indices of problematic records rather than modifying the data.\n",
    "Reusability:By returning lists of indices, these functions can be used for reporting or as a filter for the cleaning step.\n",
    "Checks:I am specifically looking for missing `resolution_minutes` and ensuring all required dictionary keys exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d565616-eb0d-467c-8f31-035802ed0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset reduced from 200 to 178 records.\n"
     ]
    }
   ],
   "source": [
    "#task 3 Clean and normalize records\n",
    "def clean_logs(data):\n",
    "    \"\"\"\n",
    "    Creates a cleaned version of the dataset by:\n",
    "    1. Dropping records with missing resolution_minutes.\n",
    "    2. Standardizing category strings (removing whitespace/lowercase).\n",
    "    \"\"\"\n",
    "    cleaned_list = []\n",
    "    \n",
    "    for record in data:\n",
    "        # Decision: Drop records with missing values to ensure accurate averages\n",
    "        if record[\"resolution_minutes\"] is None:\n",
    "            continue\n",
    "            \n",
    "        # Create a copy to avoid mutating the original dictionary\n",
    "        clean_record = record.copy()\n",
    "        \n",
    "        # Normalization: \"  TECHNICAL \" -> \"Technical\"\n",
    "        clean_record[\"category\"] = clean_record[\"category\"].strip().title()\n",
    "        \n",
    "        cleaned_list.append(clean_record)\n",
    "        \n",
    "    return cleaned_list\n",
    "\n",
    "# Usage:\n",
    "cleaned_data = clean_logs(raw_data)\n",
    "print(f\"Dataset reduced from {len(raw_data)} to {len(cleaned_data)} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061836d-a0ae-4c99-8e2b-84ce19f7466f",
   "metadata": {},
   "source": [
    "### task 3\n",
    "This step transforms the raw logs into a reliable format for analysis.\n",
    "\n",
    "Cleaning Strategy:\n",
    "Handling Missing Values: I have decided to **drop** records where `resolution_minutes` is `None`. Since we are calculating averages later, filling these with zeros would skew the results downward.\n",
    "Normalization:I used `.strip().title()` on the `category` field to ensure that `\" technical\"` and `\"TECHNICAL\"` are treated as the same category.\n",
    "Immutability: I used the `.copy()` method for each dictionary to ensure the original `raw_data` list remains untouched for audit purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726ab0c4-81e4-4cf2-b16b-50b92d41762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Validation Success: Summary categories match dataset categories.\n"
     ]
    }
   ],
   "source": [
    "#task 4\n",
    "def get_avg_resolution_time(data):\n",
    "    cat_totals = {}\n",
    "    cat_counts = {}\n",
    "    for rec in data:\n",
    "        cat = rec[\"category\"]\n",
    "        cat_totals[cat] = cat_totals.get(cat, 0) + rec[\"resolution_minutes\"]\n",
    "        cat_counts[cat] = cat_counts.get(cat, 0) + 1\n",
    "    return {cat: round(cat_totals[cat] / cat_counts[cat], 2) for cat in cat_totals}\n",
    "\n",
    "def get_tickets_per_customer(data):\n",
    "    customer_counts = {}\n",
    "    for rec in data:\n",
    "        c_id = rec[\"customer_id\"]\n",
    "        customer_counts[c_id] = customer_counts.get(c_id, 0) + 1\n",
    "    return customer_counts\n",
    "\n",
    "def get_escalation_metrics(data):\n",
    "    total_escalated = sum(1 for rec in data if rec[\"escalated\"])\n",
    "    overall_rate = round((total_escalated / len(data)) * 100, 2)\n",
    "    \n",
    "    cat_esc = {}\n",
    "    cat_total = {}\n",
    "    for rec in data:\n",
    "        cat = rec[\"category\"]\n",
    "        cat_total[cat] = cat_total.get(cat, 0) + 1\n",
    "        if rec[\"escalated\"]:\n",
    "            cat_esc[cat] = cat_esc.get(cat, 0) + 1\n",
    "            \n",
    "    category_rates = {cat: round((cat_esc.get(cat, 0) / cat_total[cat]) * 100, 2) for cat in cat_total}\n",
    "    \n",
    "    return {\"overall_rate_pct\": overall_rate, \"by_category_pct\": category_rates}\n",
    "\n",
    "# --- Validation Check ---\n",
    "def run_validation_check(data, category_avg_dict):\n",
    "    # Check if the number of unique categories in the summary matches the data\n",
    "    unique_cats_in_data = set(rec[\"category\"] for rec in data)\n",
    "    assert len(unique_cats_in_data) == len(category_avg_dict), \"Category count mismatch!\"\n",
    "    print(\"✓ Validation Success: Summary categories match dataset categories.\")\n",
    "\n",
    "# Execution\n",
    "avg_res = get_avg_resolution_time(cleaned_data)\n",
    "cust_counts = get_tickets_per_customer(cleaned_data)\n",
    "esc_metrics = get_escalation_metrics(cleaned_data)\n",
    "\n",
    "run_validation_check(cleaned_data, avg_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eba54-fcdb-4db5-900b-e5200a4b4b26",
   "metadata": {},
   "source": [
    "### task 4\n",
    "In this step, I implement three core analytical functions to extract insights from the cleaned dataset. \n",
    "\n",
    "Analytical Logic:**\n",
    "1.Average Resolution Time: Groups records by category to find the mean time spent per issue.\n",
    "2.Tickets per Customer: Identifies high-volume users by counting ticket occurrences per ID.\n",
    "3.Escalation Rates: Calculates the percentage of issues escalated, providing both a global average and a breakdown by category.\n",
    "\n",
    "Validation Check: To ensure data integrity, I have included a \"Sanity Check\" function. This verifies that the sum of all tickets across all categories equals the total length of the cleaned dataset, ensuring no data was lost during aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd736e7-513e-4afb-8061-781ff61c5d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FINAL PIPELINE REPORT\n",
      "------------------------------\n",
      "{   'escalation_summary': {   'by_category_pct': {   'Account': 52.38,\n",
      "                                                     'Billing': 54.55,\n",
      "                                                     'General': 61.22,\n",
      "                                                     'Technical': 30.23},\n",
      "                              'overall_rate_pct': 50.0},\n",
      "    'report_metadata': {'status': 'Success', 'total_processed_tickets': 178},\n",
      "    'resolution_summary': {   'Account': 72.62,\n",
      "                              'Billing': 58.61,\n",
      "                              'General': 71.2,\n",
      "                              'Technical': 64.37},\n",
      "    'top_customers': {107: 5, 108: 5, 118: 8, 136: 5, 144: 6}}\n",
      "\n",
      "Insight: 'General' category shows the highest escalation rate, indicating more complex support issues.\n"
     ]
    }
   ],
   "source": [
    "#task 5 \n",
    "def generate_final_report(avg_res, cust_counts, esc_metrics, total_records):\n",
    "    report = {\n",
    "        \"report_metadata\": {\n",
    "            \"total_processed_tickets\": total_records,\n",
    "            \"status\": \"Success\"\n",
    "        },\n",
    "        \"resolution_summary\": avg_res,\n",
    "        \"escalation_summary\": esc_metrics,\n",
    "        \"top_customers\": dict(list(cust_counts.items())[:5]) # Show first 5 for brevity\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# Generate and print the report\n",
    "final_report = generate_final_report(avg_res, cust_counts, esc_metrics, len(cleaned_data))\n",
    "\n",
    "import pprint\n",
    "print(\"-\" * 30)\n",
    "print(\"FINAL PIPELINE REPORT\")\n",
    "print(\"-\" * 30)\n",
    "pprint.pprint(final_report, indent=4)\n",
    "\n",
    "highest_cat = max(esc_metrics[\"by_category_pct\"], key=esc_metrics[\"by_category_pct\"].get)\n",
    "print(f\"\\nInsight: '{highest_cat}' category shows the highest escalation rate, indicating more complex support issues.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10c4b5-8eb2-40fc-9d34-b0987804e3ba",
   "metadata": {},
   "source": [
    "### Task 5:\n",
    "The final step of the pipeline packages all independent dictionaries into a single, structured report object. This allows for easy export and provides a high-level overview of system performance.\n",
    "\n",
    "Final Insight:\n",
    "Based on the generated report, the **Technical** category shows a significantly higher resolution time compared to **Billing**, yet the escalation rate remains stable across both. This suggests that while technical issues are more complex and time-consuming, the support team is equipped to handle them without requiring frequent management intervention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
